<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Fashion Landmark Detection in the Wild</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="Visual fashion analysis has attracted many attentions in the recent years. Previous work represented clothing regions by either bounding boxes or human joints. This work presents fashion landmark detection or fashion alignment, which is to predict the positions of functional key points defined on the fashion items, such as the corners of neckline, hemline, and cuff. To encourage future studies, we introduce a fashion landmark dataset with over 120K images, where each image is labeled with eight landmarks. With this dataset, we study fashion alignment by cascading multiple convolutional neural networks in three stages. These stages gradually improve the accuracies of landmark predictions. Extensive experiments demonstrate the effectiveness of the proposed method, as well as its generalization ability to pose estimation. Fashion landmark is also compared to clothing bounding boxes and human joints in two applications, fashion attribute prediction and clothes retrieval, showing that fashion landmark is a more discriminative representation to understand fashion images.>
<meta name="keywords" content="fashion landmarks; fashion dataset; clothes recognition; landmark detection; deep learning;">
<link rel="author" href="personal.ie.cuhk.edu.hk/~lz013/">

<!-- Fonts and stuff -->
<link href="./fashionlandmarks/css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="./fashionlandmarks/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./fashionlandmarks/iconize.css">
<script async="" src="./fashionlandmarks/prettify.js"></script>


</head>

<body>
  <div id="content">
    <div id="content-inner">
      
      <div class="section head">
	<h1>Fashion Landmark Detection in the Wild</h1>

	<div class="authors">
	  <a href="http://personal.ie.cuhk.edu.hk/~lz013/">Ziwei Liu*</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="">Sijie Yan*</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://personal.ie.cuhk.edu.hk/~pluo/">Ping Luo</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://www.ee.cuhk.edu.hk/~xgwang/">Xiaogang Wang</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://www.ie.cuhk.edu.hk/people/xotang.shtml">Xiaoou Tang</a>
	</div>

	<div class="affiliations">
	  <a href="http://mmlab.ie.cuhk.edu.hk/">Multimedia Laboratory, </a>
	  <a href="http://www.cuhk.edu.hk/english/index.html">The Chinese University of Hong Kong</a>
	</div>

	<div class="venue">European Conference on Computer Vision (<a href="http://www.eccv2016.org/" target="_blank">ECCV</a>) 2016</div>
      </div>

      
      <center><img src="./fashionlandmarks/intro.jpg" border="0" width="80%"></center>

<div class="section abstract">
	<h2>Abstract</h2>
	<br>
	<p>
Visual fashion analysis has attracted many attentions in the recent years. Previous work represented clothing regions by either bounding boxes or human joints. This work presents fashion landmark detection or fashion alignment, which is to predict the positions of functional key points defined on the fashion items, such as the corners of neckline, hemline, and cuff. To encourage future studies, we introduce a fashion landmark dataset with over 120K images, where each image is labeled with eight landmarks. With this dataset, we study fashion alignment by cascading multiple convolutional neural networks in three stages. These stages gradually improve the accuracies of landmark predictions. Extensive experiments demonstrate the effectiveness of the proposed method, as well as its generalization ability to pose estimation. Fashion landmark is also compared to clothing bounding boxes and human joints in two applications, fashion attribute prediction and clothes retrieval, showing that fashion landmark is a more discriminative representation to understand fashion images.
	</p>
      </div>

<div class="section demo">
	<h2>Demo</h2><center>
		<br>
      	<img src="./fashionlandmarks/demo.gif" border="2" width="60%">
      </div></center>

<br>
      
<div class="section materials">
	<h2>Materials</h2>
	<center>
	  <ul>
           
          <li class="grid">
	      <div class="griditem">
		<a href="https://arxiv.org/abs/1608.03049" target="_blank" class="imageLink"><img src="./fashionlandmarks/paper.jpg"></a><br>
		  <a href="https://arxiv.org/abs/1608.03049" target="_blank">Paper</a>
		</div>
	      </li>

	      <li class="grid">
	      <div class="griditem">
		<a href="../papers/fashionlandmarks_poster.pdf" target="_blank" class="imageLink"><img src="./fashionlandmarks/poster.jpg"></a><br>
		  <a href="../papers/fashionlandmarks_poster.pdf" target="_blank">Poster</a>
		</div>
	      </li>
	  
	    </ul>
	    </center>
	    </div>
	    
<br>

<div class="section code">
	<h2>Code and Models</h2>
	<center>
	  <ul>
           
          <li class="grid">
	      <div class="griditem">
		<a href="https://github.com/liuziwei7/fashion-landmarks" target="_blank" class="imageLink"><img src="./fashionlandmarks/code.png"></a><br>
		  <a href="https://github.com/liuziwei7/fashion-landmarks" target="_blank">Code and Models</a>
		</div>
	      </li>

	    </ul>
	    </center>
	    </div>
	    
<br>

<div class="section data">
	<h2>Dataset</h2>
	
	<br>

	<p><b>Fashion Landmark Detection Benchmark</b> evaluates the performance of fashion landmark detection. This is a large subset of <a href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html" target="_blank">DeepFashion</a>, with diverse and large pose/zoom-in variations. It contains</p>

      <ul>
	  <li><p><b>123,016</b> number of <b>clothes images</b>;</p>
	  </li>
	  <li><p><b>8 fashion landmarks (both location and visibility)</b> for each image;</p>
	  <li><p>Each image is also annotated by <b>bounding box</b>, <b>clothing type</b> and <b>variation type</b>.</p>
	  </li>
	  </ul>
		<br>
		<center>
      	<a href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/LandmarkDetection.html" target="_blank" class="imageLink"><img src="./fashionlandmarks/dataset.jpg" border="2" width="70%"></a><br>
      	<a href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/LandmarkDetection.html" target="_blank">Fashion Landmark Detection Benchmark</a>
      </div></center>



<div class="section citation">
	<h2>Citation</h2>
	<div class="section bibtex">
	  <pre>@inproceedings{liu2016fashionlandmark,
 author = {Ziwei Liu, Sijie Yan, Ping Luo, Xiaogang Wang, and Xiaoou Tang},
 title = {Fashion Landmark Detection in the Wild},
 booktitle = {European Conference on Computer Vision (ECCV)},
 month = October,
 year = {2016} 
}</pre>
	  </div>
      </div>

</body></html>