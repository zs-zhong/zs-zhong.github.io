<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html class="gr__ai_stanford_edu"><head> 
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-93062604-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-93062604-2'); 
  </script>
</head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 600
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <style type="text/css">
    #sectiontohide {
      padding: 20px;
      background: #f0f0f0;
      width: 400px;
    }
  </style>
  <script type="text/javascript">
    function toggle_div_fun(id) {

      var divelement = document.getElementById(id);

      if (divelement.style.display == 'none')
        divelement.style.display = 'block';
      else
        divelement.style.display = 'none';
    }
  </script>
  <link rel="icon" type="image/png" href="../assets/cv/cuhk.png">
  <title>Yilun Chen</title>

<body data-gr-c-s-loaded="true">
  <table width="1050" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Yilun Chen</name>
              </p>
              <p>
                I am currently a fourth-year PhD student at Computer Science & Engineering Department, <a href="https://www.cse.cuhk.edu.hk/en/">The Chinese University of Hong Kong</a>, under the supervision of <a href="http://jiaya.me/">Prof. Jiaya Jia</a>.
              </p>
              <p>
                I have a great time to do research with <a href="http://shuliu.me/">Dr. Shu Liu</a> and <a href="http://xiaoyongshen.me/">Dr. Xiaoyong Shen</a> as a research intern at <a href="https://smartmore.global/">SMartMore Inc.</a> as well as <a href="https://open.youtu.qq.com/#/open"> Youtu X-Lab </a> at <a href="http://www.tencent.com/en-us/index.html">Tencent</a>.
                Before that, I was lucky to work with <a href="http://www.skicyyu.org/">Dr. Gang Yu</a> and <a href="http://www.jiansun.org/">Dr. Jian Sun</a>       
                </a> during my internship in <a href="https://www.megvii.com/en/">Megvii (Face++) Research</a>. 
              </p>
              <p>
                My research interests lie primarily in computer vision and deep learning,
                particularly focusing on <b>3D object detection and scene understanding</b>.
              </p>
              <p align="center">
                <a href="mailto:ylchen@cse.cuhk.edu.hk"> Email </a> /
                <a href="https://www.linkedin.com/in/yilunchen-cuhk"> LinkedIn </a> /
                <a href="https://scholar.google.com/citations?user=gKXC9Q8AAAAJ&hl=en"> Google Scholar </a> /
                <a href="https://github.com/chenyilun95"> Github </a>
              </p>
            </td>
            <td width="33%">
              <img src="../assets/cv/yilun_chen.jpg" width="150" height="200">
            </td>
          </tr>
        </tbody></table>

        <!--##################### News ####################-->
        <br><br>
         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
              <heading>Timeline</heading>
          </tr>
        </tbody></table>

         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <p>
            <ul>
                <li>[Sep 2022] One paper is accepted by NeurIPS 2022. </li>
                <li>[Aug 2022] DSGN++ is accepted by T-PAMI 2022 and code is available. </li>
                <li>[March 2022] Two papers got accepted by CVPR2022. </li>
                <li>[April 2020] Code for DSGN is released! </li>
                <li>[March 2020] DSGN is accepted by CVPR 2020.</li>
                <li>[June 2019] Fast Point R-CNN is accepted by ICCV 2019. </li>
                <li>[March 2018] Joined Youtu-Lab at Tencent as a research intern.</li>
                <li>[February 2018] One paper is accepted by CVPR 2018</li>
                <li>[Oct 2017] Won <b>1st Place</b> in <a href="https://places-coco2017.github.io/"> COCO 2017 Keypoint Challenge </a> </li>
                <li>[Nov 2016] Joined Megvii Face++ as a research intern.</li>
            </ul>
            </p>
          </tr>
        </tbody></table>
        </br>

        <!-- <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Tech Reports</heading> 
          </tr>
        </table>

        </br> -->

        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Publications</heading>
          </tr>
        </table>

        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/dsgn2.png" alt="DSGN++" width="230" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>DSGN++: Exploiting Visual-Spatial Relation for Stereo-based 3D Detectors</papertitle>
                <br>
                <strong>Yilun Chen</strong>, Shijia Huang, <a href="http://shuliu.me/">Shu Liu</a>, <a href="http://www.cse.cuhk.edu.hk/~byu/">Bei Yu</a>, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>T-PAMI</strong>), 2022 (accepted)</em> 
                <br>
                <font color="ff0000" size="2"><em>Ranked 1st place among all camera-based approaches on KITTI 3D detection leaderboard (All categories, Nov. 2021).</em></font>
                <br>
                <a href="https://arxiv.org/pdf/2204.03039.pdf">[PDF]</a> <a href="https://github.com/chenyilun95/DSGN2">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/uvtr.jpg" alt="UVTR" width="230" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Unifying Voxel-based Representation with Transformer for 3D Object Detection</papertitle>
                <br>
                <a href="https://yanwei-li.com/">Yanwei Li</a>, <strong>Yilun Chen</strong>, , <a href="https://xjqi.github.io/">Xiaojuan Qi</a>, <a href="http://www.zemingli.com">Zeming Li</a>, <a href="http://www.jiansun.org/">Jian Sun</a>, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em> Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2022</em> 
                <br>
                <a href="https://arxiv.org/pdf/2206.00630.pdf">[PDF]</a> <a href="https://github.com/dvlab-research/UVTR">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/mvt.png" alt="dsgn" width="210" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Multi-View Transformer for 3D Visual Grounding</papertitle>
                <br>
                Shijia Huang, <strong>Yilun Chen</strong>, <a href="http://jiaya.me/">Jiaya Jia</a>, <a href="https://lwwangcse.github.io/">Liwei Wang</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022</em>
                <br>
                <a href="https://arxiv.org/pdf/2204.02174.pdf">[PDF]</a> <a href="https://github.com/sega-hsj/MVT-3DVG">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/efficientnerf.png" alt="dsgn" width="210" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Efficient Neural Radiance Fields</papertitle>
                <br>
                Tao Hu, <a href="http://shuliu.me/">Shu Liu</a>, <strong>Yilun Chen</strong>, Tiancheng Shen, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022</em>
                <br>
                [PDF] [Code]
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/dsgn_pipeline.jpg" alt="dsgn" width="230" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>DSGN: Deep Stereo Geometry Network for 3D Object Detection</papertitle>
                <br>
                <strong>Yilun Chen</strong>, <a href="http://shuliu.me/">Shu Liu</a>, <a href="http://xiaoyongshen.me/">Xiaoyong Shen</a>, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2020</em> 
                <br>
                <font color="ff0000" size="2"><em>Ranked 1st place among all camera-based approaches on KITTI 3D detection leaderboard (All categories, Nov. 2019).</em></font>
                <br>
                <a href="https://arxiv.org/pdf/2001.03398.pdf">[PDF]</a> <a href="https://github.com/chenyilun95/DSGN">[Project Page]</a> <a href="https://github.com/chenyilun95/DSGN">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/fprcnn_pipeline.jpg" alt="fprcnn" width="200" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Fast Point R-CNN</papertitle>
                <br>
                <strong>Yilun Chen</strong>, <a href="http://shuliu.me/">Shu Liu</a>, <a href="http://xiaoyongshen.me/">Xiaoyong Shen</a>, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>) </em>, 2019
                <br>
                <a href="../assets/cv/paper/Chen_Fast_Point_R-CNN_ICCV_2019_paper.pdf">[PDF]</a> [project page] <a href="../assets/cv/bibtex/fastpointrcnn.txt">[bibtex]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/cpn_pipeline.jpg" alt="cpn" width="140" height="110">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Cascaded Pyramid Network for Multi-Person Pose Estimation</papertitle>
                <br>
                <strong>Yilun Chen</strong>*, Zhicheng Wang*, Yuxiang Peng, Zhiqiang Zhang, <a href="http://www.skicyyu.org/">Gang Yu</a>, <a href="http://www.jiansun.org/">Jian Sun</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2018
                <br>
                <font color="ff0000" size="2"><em>Champion of COCO 2017 Keypoint Challenge.</em></font>
                <br>
                <a href="../assets/cv/paper/Chen_Cascaded_Pyramid_Network_CVPR_2018_paper.pdf">[PDF]</a> [project page] <a href="https://github.com/chenyilun95/tf-cpn">[Code]</a> <a href="../assets/cv/bibtex/cpn.txt">[bibtex]</a>
                <br>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/rfcnplusplus.jpg" alt="rfcn++" width="160" height="140">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>R-FCN++: Towards Accurate Region-based Fully Convolutional Networks for Object Detection</papertitle>
                <br>
                <a href="http://www.zemingli.com/">Zeming Li</a>, <strong>Yilun Chen</strong>, <a href="http://www.skicyyu.org/">Gang Yu</a>, Yangdong Deng
                <br>
                <em>Thirty-Second AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, 2018
                <br>
                <a href="../assets/cv/paper/RFCN_plus_plus.pdf">[PDF]</a> <a href="../assets/cv/bibtex/rfcnpp.txt">[bibtex]</a>
                <br>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Experience</heading>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tbody><tr>
              <td width="25%" align="center">
                <img src="../assets/cv/smartmore.png" alt="smartmore" width="140" height="42">
              </td>
              <td width="75%" valign="top">
                    <strong>Mar. 2020 - June. 2022</strong>, <i><b>SmartMore Inc.</b></i><br> Intern Mentor: Shu Liu <br>
              <!-- <p>
                  Working on 3D object detection based on point cloud and stereo image pair for autonomous driving.
              </p> -->
              </td>
            </tr>
          </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="10">
        <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/tencent.png" alt="tencent" width="180" height="62">
            </td>
            <td width="75%" valign="top">
                  <strong>Mar. 2018 - Jan. 2020</strong>, <i><b>Tecent Youtu, X-Lab</b></i><br> Intern Mentor: Shu Liu <br>
            <!-- <p>
                Working on 3D object detection based on point cloud and stereo image pair for autonomous driving.
            </p> -->
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="10">
        <tbody><tr>
          <td width="25%" align="center">
            <img src="../assets/cv/face.png" alt="face" width="150" height="32">
          </td>
          <td width="75%" valign="top">
                <strong>Nov. 2016 - Nov. 2017</strong>, <i><b>Megvii Face++</b></i><br> Intern Mentor: Gang Yu <br>
          <!-- <p>
              Working on human pose estimation and general object detection in Detection Team.
          </p> -->
          </td>
        </tr>
        </tbody></table>

        <br><br>
        
        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Education</heading>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
         <tbody><tr>
           <td width="25%" align="center">
             <img src="../assets/cv/cuhk.png" alt="cuhk" width="78" height="78">
           </td>
           <td width="75%" valign="top">
              <p>
                <strong>Aug. 2018 - Present </strong>,
                <i>
                  <b>The Chinese University of Hong Kong</b>
                </i>,</p>
              <p>Ph.D. Student, Computer Science & Engineering<br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="10">
         <tbody><tr>
           <td width="25%" align="center">
             <img src="../assets/cv/bhu.png" alt="cuhk" width="78" height="78">
           </td>
           <td width="75%" valign="top">
              <p>
                <strong>Aug. 2013 - July. 2017 </strong>,
                <i>
                  <b>BeiHang University</b>
                </i>,</p>
              <p>Bachelor Degree, Computer Science & Engineering<br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Service</heading>
          </tr>
        </table>
        
        <ul>
          <li>
            <p>Conference Reviewer: CVPR2020-2022, ECCV 2020, ICCV 2019,2021, ICLR 2022, NeurIPS 2022, ICRA 2021, IROS 2022</p>
          </li>
          <li>
            <p>Jounral Reviewer: T-PAMI</p>
          </li>
          <li>
            <p>Teaching: CSCI3310, CSCI3180, CSCI1120, ENGG1100</p>
          </li>
        </ul>

        <br>
        <!-- Footer ================================================== -->
        <hr>
        <footer class="footer">
          <div class="container">
            <p>
              &nbsp;&nbsp;&nbsp;Updated Sep. 2022</p>
            <p></p>
            <p align="right">
              <a href="https://jonbarron.info/"> Page Template </a>
              <a class="pull-right" href="#">
                <!-- <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=c8c9c7&w=a&t=tt&d=10J0WdrxpXVNYP-lh84CaMXnme4gafH_7bKD0A6u-34&cmn=dbbd21&co=3373a1"></script> -->
                <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=n&d=10J0WdrxpXVNYP-lh84CaMXnme4gafH_7bKD0A6u-34&w=268'></script>
              </a>
            </p>
          </div>
        </footer>
        </hr>      

      </td>
    </tr>
  </tbody></table>


<div class="jvectormap-tip"></div></body></html>
