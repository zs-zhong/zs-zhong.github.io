<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html class="gr__ai_stanford_edu"><head> 
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-93062604-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-93062604-2'); 
  </script>
</head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 600
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <style type="text/css">
    #sectiontohide {
      padding: 20px;
      background: #f0f0f0;
      width: 400px;
    }
  </style>
  <script type="text/javascript">
    function toggle_div_fun(id) {

      var divelement = document.getElementById(id);

      if (divelement.style.display == 'none')
        divelement.style.display = 'block';
      else
        divelement.style.display = 'none';
    }
  </script>
  <link rel="icon" type="image/png" href="./pic/cuhk.png">
  <title>Zhisheng Zhong</title>

<body data-gr-c-s-loaded="true">
  <table width="1050" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Zhisheng Zhong</name>
              </p>
              <p>
                I am currently a PhD student at Computer Science & Engineering Department, <a href="https://www.cse.cuhk.edu.hk/en/">The Chinese University of Hong Kong</a>, under the supervision of <a href="http://jiaya.me/">Prof. Jiaya Jia</a>.
              </p>
              <p>
                
                Before that, I obtained the Master degree in Intelligence Science, <a href="https://english.pku.edu.cn/">Peking University</a> in 2019, supervised by <a href="https://zhouchenlin.github.io/">Prof. Zhouchen Lin</a> and <a href="https://scholar.google.com.hk/citations?user=NeCCx-kAAAAJ&hl=en">Prof. Chao Zhang</a>. I received the Bachelor degree in Telecommunication Engineering from <a href="https://www.bupt.edu.cn/">Beijing University Of Posts And Telecommunications</a> in 2016.
              </p>
              <p>
                My current research interests lie primarily in computer vision and machine learning,
                particularly focusing on <b>Imbalanced Learning, and 2D/3D Segmentation</b>.
              </p>
              <p align="center">
                <a href="mailto:zszhong@link.cuhk.edu.hk"> Email </a> /
                <!-- <a href="https://www.linkedin.com/in/yilunchen-cuhk"> LinkedIn </a> / -->
                <a href="https://scholar.google.com/citations?user=u-2_7C8AAAAJ&hl=en"> Google Scholar </a> /
                <a href="https://github.com/zs-zhong"> Github </a>
              </p>
            </td>
            <td width="33%">
              <img src="./pic/zhishengzhong.JPG" width="200" height="200">
            </td>
          </tr>
        </tbody></table>

        <!--##################### News ####################-->
        <br><br>
         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
              <heading>Timeline</heading>
          </tr>
        </tbody></table>

         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <p>
            <ul>
                <!-- <li>[Sep 2022] One paper is accepted by NeurIPS 2022. </li> -->
            </ul>
            </p>
          </tr>
        </tbody></table>
        </br>

        <!-- <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Tech Reports</heading> 
          </tr>
        </table>

        </br> -->

        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Publications</heading>
          </tr>
        </table>

        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./pic/dsgn2.png" alt="DSGN++" width="230" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>DSGN++: Exploiting Visual-Spatial Relation for Stereo-based 3D Detectors</papertitle>
                <br>
                <strong>Zhisheng Zhong</strong>, Shijia Huang, <a href="http://shuliu.me/">Shu Liu</a>, <a href="http://www.cse.cuhk.edu.hk/~byu/">Bei Yu</a>, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>T-PAMI</strong>), 2022 (accepted)</em> 
                <br>
                <font color="ff0000" size="2"><em>Ranked 1st place among all camera-based approaches on KITTI 3D detection leaderboard (All categories, Nov. 2021).</em></font>
                <br>
                <a href="https://arxiv.org/pdf/2204.03039.pdf">[PDF]</a> <a href="https://github.com/chenyilun95/DSGN2">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./pic/uvtr.jpg" alt="UVTR" width="230" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Unifying Voxel-based Representation with Transformer for 3D Object Detection</papertitle>
                <br>
                <a href="https://yanwei-li.com/">Yanwei Li</a>, <strong>Zhisheng Zhong</strong>, <a href="https://xjqi.github.io/">Xiaojuan Qi</a>, <a href="http://www.zemingli.com">Zeming Li</a>, <a href="http://www.jiansun.org/">Jian Sun</a>, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em> Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2022</em> 
                <br>
                <a href="https://arxiv.org/pdf/2206.00630.pdf">[PDF]</a> <a href="https://github.com/dvlab-research/UVTR">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./pic/mvt.png" alt="dsgn" width="210" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Multi-View Transformer for 3D Visual Grounding</papertitle>
                <br>
                Shijia Huang, <strong>Zhisheng Zhong</strong>, <a href="http://jiaya.me/">Jiaya Jia</a>, <a href="https://lwwangcse.github.io/">Liwei Wang</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022</em>
                <br>
                <a href="https://arxiv.org/pdf/2204.02174.pdf">[PDF]</a> <a href="https://github.com/sega-hsj/MVT-3DVG">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./pic/efficientnerf.png" alt="dsgn" width="210" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Efficient Neural Radiance Fields</papertitle>
                <br>
                Tao Hu, <a href="http://shuliu.me/">Shu Liu</a>, <strong>Zhisheng Zhong</strong>, Tiancheng Shen, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022</em>
                <br>
                [PDF] [Code]
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./pic/dsgn_pipeline.jpg" alt="dsgn" width="230" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>DSGN: Deep Stereo Geometry Network for 3D Object Detection</papertitle>
                <br>
                <strong>Zhisheng Zhong</strong>, <a href="http://shuliu.me/">Shu Liu</a>, <a href="http://xiaoyongshen.me/">Xiaoyong Shen</a>, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2020</em> 
                <br>
                <font color="ff0000" size="2"><em>Ranked 1st place among all camera-based approaches on KITTI 3D detection leaderboard (All categories, Nov. 2019).</em></font>
                <br>
                <a href="https://arxiv.org/pdf/2001.03398.pdf">[PDF]</a> <a href="https://github.com/chenyilun95/DSGN">[Project Page]</a> <a href="https://github.com/chenyilun95/DSGN">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./pic/fprcnn_pipeline.jpg" alt="fprcnn" width="200" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Fast Point R-CNN</papertitle>
                <br>
                <strong>Zhisheng Zhong</strong>, <a href="http://shuliu.me/">Shu Liu</a>, <a href="http://xiaoyongshen.me/">Xiaoyong Shen</a>, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>) </em>, 2019
                <br>
                <a href="./pic/paper/Chen_Fast_Point_R-CNN_ICCV_2019_paper.pdf">[PDF]</a> [project page] <a href="./pic/bibtex/fastpointrcnn.txt">[bibtex]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./pic/cpn_pipeline.jpg" alt="cpn" width="140" height="110">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Cascaded Pyramid Network for Multi-Person Pose Estimation</papertitle>
                <br>
                <strong>Zhisheng Zhong</strong>*, Zhicheng Wang*, Yuxiang Peng, Zhiqiang Zhang, <a href="http://www.skicyyu.org/">Gang Yu</a>, <a href="http://www.jiansun.org/">Jian Sun</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2018
                <br>
                <font color="ff0000" size="2"><em>Champion of COCO 2017 Keypoint Challenge.</em></font>
                <br>
                <a href="./pic/paper/Chen_Cascaded_Pyramid_Network_CVPR_2018_paper.pdf">[PDF]</a> [project page] <a href="https://github.com/chenyilun95/tf-cpn">[Code]</a> <a href="./pic/bibtex/cpn.txt">[bibtex]</a>
                <br>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="./pic/rfcnplusplus.jpg" alt="rfcn++" width="160" height="140">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>R-FCN++: Towards Accurate Region-based Fully Convolutional Networks for Object Detection</papertitle>
                <br>
                <a href="http://www.zemingli.com/">Zeming Li</a>, <strong>Zhisheng Zhong</strong>, <a href="http://www.skicyyu.org/">Gang Yu</a>, Yangdong Deng
                <br>
                <em>Thirty-Second AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, 2018
                <br>
                <a href="./pic/paper/RFCN_plus_plus.pdf">[PDF]</a> <a href="./pic/bibtex/rfcnpp.txt">[bibtex]</a>
                <br>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Experience</heading>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tbody><tr>
              <td width="25%" align="center">
                <img src="./pic/smartmore.png" alt="smartmore" width="140" height="42">
              </td>
              <td width="75%" valign="top">
                    <strong>Mar. 2020 - June. 2022</strong>, <i><b>SmartMore Inc.</b></i><br> Intern Mentor: Shu Liu <br>
              <!-- <p>
                  Working on 3D object detection based on point cloud and stereo image pair for autonomous driving.
              </p> -->
              </td>
            </tr>
          </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="10">
        <tbody><tr>
            <td width="25%" align="center">
              <img src="./pic/tencent.png" alt="tencent" width="180" height="62">
            </td>
            <td width="75%" valign="top">
                  <strong>Mar. 2018 - Jan. 2020</strong>, <i><b>Tecent Youtu, X-Lab</b></i><br> Intern Mentor: Shu Liu <br>
            <!-- <p>
                Working on 3D object detection based on point cloud and stereo image pair for autonomous driving.
            </p> -->
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="10">
        <tbody><tr>
          <td width="25%" align="center">
            <img src="./pic/face.png" alt="face" width="150" height="32">
          </td>
          <td width="75%" valign="top">
                <strong>Nov. 2016 - Nov. 2017</strong>, <i><b>Megvii Face++</b></i><br> Intern Mentor: Gang Yu <br>
          <!-- <p>
              Working on human pose estimation and general object detection in Detection Team.
          </p> -->
          </td>
        </tr>
        </tbody></table>

        <br><br>
        

        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Service</heading>
          </tr>
        </table>
        
        <ul>
          <li>
            <p>Conference Reviewer: CVPR2020-2022, ECCV 2020, ICCV 2019,2021, ICLR 2021-2023, NeurIPS 2021-2023</p>
          </li>
          <li>
            <p>Jounral Reviewer: T-PAMI, T-NNLS, T-CSVT</p>
          </li>
          <li>
            <p>Teaching: ENGG5104 Image Processing and Computer Vision, CENG3420 Computer Organization & Design, ENGG1110 Problem Solving By Programming</p>
          </li>
        </ul>

        <br>
        <!-- Footer ================================================== -->
        <hr>
        <footer class="footer">
          <div class="container">
            <p>
              &nbsp;&nbsp;&nbsp;Updated Nov. 2022</p>
            <p></p>
            <p align="right">
              <a href="https://jonbarron.info/"> Page Template </a>
              <a class="pull-right" href="#">
                <!-- <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=c8c9c7&w=a&t=tt&d=10J0WdrxpXVNYP-lh84CaMXnme4gafH_7bKD0A6u-34&cmn=dbbd21&co=3373a1"></script> -->
                <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=n&d=10J0WdrxpXVNYP-lh84CaMXnme4gafH_7bKD0A6u-34&w=268'></script>
              </a>
            </p>
          </div>
        </footer>
        </hr>      

      </td>
    </tr>
  </tbody></table>


<div class="jvectormap-tip"></div></body></html>
