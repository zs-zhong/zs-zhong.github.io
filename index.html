<<<<<<< HEAD
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html class="gr__ai_stanford_edu"><head> 
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-93062604-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-93062604-2'); 
  </script>
</head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 600
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <style type="text/css">
    #sectiontohide {
      padding: 20px;
      background: #f0f0f0;
      width: 400px;
    }
  </style>
  <script type="text/javascript">
    function toggle_div_fun(id) {

      var divelement = document.getElementById(id);

      if (divelement.style.display == 'none')
        divelement.style.display = 'block';
      else
        divelement.style.display = 'none';
    }
  </script>
  <link rel="icon" type="image/png" href="../assets/cv/cuhk.png">
  <title>Yilun Chen</title>

<body data-gr-c-s-loaded="true">
  <table width="1050" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Yilun Chen</name>
              </p>
              <p>
                I am currently a fourth-year PhD student at Computer Science & Engineering Department, <a href="https://www.cse.cuhk.edu.hk/en/">The Chinese University of Hong Kong</a>, under the supervision of <a href="http://jiaya.me/">Prof. Jiaya Jia</a>.
              </p>
              <p>
                I have a great time to do research with <a href="http://shuliu.me/">Dr. Shu Liu</a> and <a href="http://xiaoyongshen.me/">Dr. Xiaoyong Shen</a> as a research intern at <a href="https://smartmore.global/">SMartMore Inc.</a> as well as <a href="https://open.youtu.qq.com/#/open"> Youtu X-Lab </a> at <a href="http://www.tencent.com/en-us/index.html">Tencent</a>.
                Before that, I was lucky to work with <a href="http://www.skicyyu.org/">Dr. Gang Yu</a> and <a href="http://www.jiansun.org/">Dr. Jian Sun</a>       
                </a> during my internship in <a href="https://www.megvii.com/en/">Megvii (Face++) Research</a>. 
              </p>
              <p>
                My research interests lie primarily in computer vision and deep learning,
                particularly focusing on <b>3D object detection and scene understanding</b>.
              </p>
              <p align="center">
                <a href="mailto:ylchen@cse.cuhk.edu.hk"> Email </a> /
                <a href="https://www.linkedin.com/in/yilunchen-cuhk"> LinkedIn </a> /
                <a href="https://scholar.google.com/citations?user=gKXC9Q8AAAAJ&hl=en"> Google Scholar </a> /
                <a href="https://github.com/chenyilun95"> Github </a>
              </p>
            </td>
            <td width="33%">
              <img src="../assets/cv/yilun_chen.jpg" width="150" height="200">
            </td>
          </tr>
        </tbody></table>

        <!--##################### News ####################-->
        <br><br>
         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
              <heading>Timeline</heading>
          </tr>
        </tbody></table>

         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <p>
            <ul>
                <li>[Sep 2022] One paper is accepted by NeurIPS 2022. </li>
                <li>[Aug 2022] DSGN++ is accepted by T-PAMI 2022 and code is available. </li>
                <li>[March 2022] Two papers got accepted by CVPR2022. </li>
                <li>[April 2020] Code for DSGN is released! </li>
                <li>[March 2020] DSGN is accepted by CVPR 2020.</li>
                <li>[June 2019] Fast Point R-CNN is accepted by ICCV 2019. </li>
                <li>[March 2018] Joined Youtu-Lab at Tencent as a research intern.</li>
                <li>[February 2018] One paper is accepted by CVPR 2018</li>
                <li>[Oct 2017] Won <b>1st Place</b> in <a href="https://places-coco2017.github.io/"> COCO 2017 Keypoint Challenge </a> </li>
                <li>[Nov 2016] Joined Megvii Face++ as a research intern.</li>
            </ul>
            </p>
          </tr>
        </tbody></table>
        </br>

        <!-- <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Tech Reports</heading> 
          </tr>
        </table>

        </br> -->

        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Publications</heading>
          </tr>
        </table>

        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/dsgn2.png" alt="DSGN++" width="230" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>DSGN++: Exploiting Visual-Spatial Relation for Stereo-based 3D Detectors</papertitle>
                <br>
                <strong>Yilun Chen</strong>, Shijia Huang, <a href="http://shuliu.me/">Shu Liu</a>, <a href="http://www.cse.cuhk.edu.hk/~byu/">Bei Yu</a>, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>T-PAMI</strong>), 2022 (accepted)</em> 
                <br>
                <font color="ff0000" size="2"><em>Ranked 1st place among all camera-based approaches on KITTI 3D detection leaderboard (All categories, Nov. 2021).</em></font>
                <br>
                <a href="https://arxiv.org/pdf/2204.03039.pdf">[PDF]</a> <a href="https://github.com/chenyilun95/DSGN2">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/uvtr.jpg" alt="UVTR" width="230" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Unifying Voxel-based Representation with Transformer for 3D Object Detection</papertitle>
                <br>
                <a href="https://yanwei-li.com/">Yanwei Li</a>, <strong>Yilun Chen</strong>, , <a href="https://xjqi.github.io/">Xiaojuan Qi</a>, <a href="http://www.zemingli.com">Zeming Li</a>, <a href="http://www.jiansun.org/">Jian Sun</a>, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em> Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2022</em> 
                <br>
                <a href="https://arxiv.org/pdf/2206.00630.pdf">[PDF]</a> <a href="https://github.com/dvlab-research/UVTR">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/mvt.png" alt="dsgn" width="210" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Multi-View Transformer for 3D Visual Grounding</papertitle>
                <br>
                Shijia Huang, <strong>Yilun Chen</strong>, <a href="http://jiaya.me/">Jiaya Jia</a>, <a href="https://lwwangcse.github.io/">Liwei Wang</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022</em>
                <br>
                <a href="https://arxiv.org/pdf/2204.02174.pdf">[PDF]</a> <a href="https://github.com/sega-hsj/MVT-3DVG">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/efficientnerf.png" alt="dsgn" width="210" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Efficient Neural Radiance Fields</papertitle>
                <br>
                Tao Hu, <a href="http://shuliu.me/">Shu Liu</a>, <strong>Yilun Chen</strong>, Tiancheng Shen, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022</em>
                <br>
                [PDF] [Code]
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/dsgn_pipeline.jpg" alt="dsgn" width="230" height="80">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>DSGN: Deep Stereo Geometry Network for 3D Object Detection</papertitle>
                <br>
                <strong>Yilun Chen</strong>, <a href="http://shuliu.me/">Shu Liu</a>, <a href="http://xiaoyongshen.me/">Xiaoyong Shen</a>, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2020</em> 
                <br>
                <font color="ff0000" size="2"><em>Ranked 1st place among all camera-based approaches on KITTI 3D detection leaderboard (All categories, Nov. 2019).</em></font>
                <br>
                <a href="https://arxiv.org/pdf/2001.03398.pdf">[PDF]</a> <a href="https://github.com/chenyilun95/DSGN">[Project Page]</a> <a href="https://github.com/chenyilun95/DSGN">[Code]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/fprcnn_pipeline.jpg" alt="fprcnn" width="200" height="100">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Fast Point R-CNN</papertitle>
                <br>
                <strong>Yilun Chen</strong>, <a href="http://shuliu.me/">Shu Liu</a>, <a href="http://xiaoyongshen.me/">Xiaoyong Shen</a>, <a href="http://jiaya.me/">Jiaya Jia</a>
                <br>
                <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>) </em>, 2019
                <br>
                <a href="../assets/cv/paper/Chen_Fast_Point_R-CNN_ICCV_2019_paper.pdf">[PDF]</a> [project page] <a href="../assets/cv/bibtex/fastpointrcnn.txt">[bibtex]</a>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/cpn_pipeline.jpg" alt="cpn" width="140" height="110">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>Cascaded Pyramid Network for Multi-Person Pose Estimation</papertitle>
                <br>
                <strong>Yilun Chen</strong>*, Zhicheng Wang*, Yuxiang Peng, Zhiqiang Zhang, <a href="http://www.skicyyu.org/">Gang Yu</a>, <a href="http://www.jiansun.org/">Jian Sun</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2018
                <br>
                <font color="ff0000" size="2"><em>Champion of COCO 2017 Keypoint Challenge.</em></font>
                <br>
                <a href="../assets/cv/paper/Chen_Cascaded_Pyramid_Network_CVPR_2018_paper.pdf">[PDF]</a> [project page] <a href="https://github.com/chenyilun95/tf-cpn">[Code]</a> <a href="../assets/cv/bibtex/cpn.txt">[bibtex]</a>
                <br>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/rfcnplusplus.jpg" alt="rfcn++" width="160" height="140">
            </td>
            <td width="75%" valign="top">
              <p>
                <papertitle>R-FCN++: Towards Accurate Region-based Fully Convolutional Networks for Object Detection</papertitle>
                <br>
                <a href="http://www.zemingli.com/">Zeming Li</a>, <strong>Yilun Chen</strong>, <a href="http://www.skicyyu.org/">Gang Yu</a>, Yangdong Deng
                <br>
                <em>Thirty-Second AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, 2018
                <br>
                <a href="../assets/cv/paper/RFCN_plus_plus.pdf">[PDF]</a> <a href="../assets/cv/bibtex/rfcnpp.txt">[bibtex]</a>
                <br>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Experience</heading>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
          <tbody><tr>
              <td width="25%" align="center">
                <img src="../assets/cv/smartmore.png" alt="smartmore" width="140" height="42">
              </td>
              <td width="75%" valign="top">
                    <strong>Mar. 2020 - June. 2022</strong>, <i><b>SmartMore Inc.</b></i><br> Intern Mentor: Shu Liu <br>
              <!-- <p>
                  Working on 3D object detection based on point cloud and stereo image pair for autonomous driving.
              </p> -->
              </td>
            </tr>
          </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="10">
        <tbody><tr>
            <td width="25%" align="center">
              <img src="../assets/cv/tencent.png" alt="tencent" width="180" height="62">
            </td>
            <td width="75%" valign="top">
                  <strong>Mar. 2018 - Jan. 2020</strong>, <i><b>Tecent Youtu, X-Lab</b></i><br> Intern Mentor: Shu Liu <br>
            <!-- <p>
                Working on 3D object detection based on point cloud and stereo image pair for autonomous driving.
            </p> -->
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="10">
        <tbody><tr>
          <td width="25%" align="center">
            <img src="../assets/cv/face.png" alt="face" width="150" height="32">
          </td>
          <td width="75%" valign="top">
                <strong>Nov. 2016 - Nov. 2017</strong>, <i><b>Megvii Face++</b></i><br> Intern Mentor: Gang Yu <br>
          <!-- <p>
              Working on human pose estimation and general object detection in Detection Team.
          </p> -->
          </td>
        </tr>
        </tbody></table>

        <br><br>
        
        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Education</heading>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="10">
         <tbody><tr>
           <td width="25%" align="center">
             <img src="../assets/cv/cuhk.png" alt="cuhk" width="78" height="78">
           </td>
           <td width="75%" valign="top">
              <p>
                <strong>Aug. 2018 - Present </strong>,
                <i>
                  <b>The Chinese University of Hong Kong</b>
                </i>,</p>
              <p>Ph.D. Student, Computer Science & Engineering<br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="10">
         <tbody><tr>
           <td width="25%" align="center">
             <img src="../assets/cv/bhu.png" alt="cuhk" width="78" height="78">
           </td>
           <td width="75%" valign="top">
              <p>
                <strong>Aug. 2013 - July. 2017 </strong>,
                <i>
                  <b>BeiHang University</b>
                </i>,</p>
              <p>Bachelor Degree, Computer Science & Engineering<br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
                <heading>Service</heading>
          </tr>
        </table>
        
        <ul>
          <li>
            <p>Conference Reviewer: CVPR2020-2022, ECCV 2020, ICCV 2019,2021, ICLR 2022, NeurIPS 2022, ICRA 2021, IROS 2022</p>
          </li>
          <li>
            <p>Jounral Reviewer: T-PAMI</p>
          </li>
          <li>
            <p>Teaching: CSCI3310, CSCI3180, CSCI1120, ENGG1100</p>
          </li>
        </ul>

        <br>
        <!-- Footer ================================================== -->
        <hr>
        <footer class="footer">
          <div class="container">
            <p>
              &nbsp;&nbsp;&nbsp;Updated Sep. 2022</p>
            <p></p>
            <p align="right">
              <a href="https://jonbarron.info/"> Page Template </a>
              <a class="pull-right" href="#">
                <!-- <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=c8c9c7&w=a&t=tt&d=10J0WdrxpXVNYP-lh84CaMXnme4gafH_7bKD0A6u-34&cmn=dbbd21&co=3373a1"></script> -->
                <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=n&d=10J0WdrxpXVNYP-lh84CaMXnme4gafH_7bKD0A6u-34&w=268'></script>
              </a>
            </p>
          </div>
        </footer>
        </hr>      

      </td>
    </tr>
  </tbody></table>


<div class="jvectormap-tip"></div></body></html>
=======
<html>
<head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
  <title>Zhisheng Zhong</title>
  <meta content="Zhisheng Zhong; 钟之声; Computer Vision; Deep Learning; Peking University; PKU" name="keywords" />
  <style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
a {
  color: #1772d0;
  text-decoration:none;
}
a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}
a.paper {
  font-weight: bold;
  font-size: 14pt;
}
b.paper {
  font-weight: bold;
  font-size: 14pt;
}
* {
  margin: 0pt;
  padding: 0pt;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 1000px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  background: #eee;
}
h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 17pt;
  font-weight: 700;
}
h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 18px;
  font-weight: 700;
}
strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15px;
  font-weight:bold;
}
ul { 
  list-style: circle;
}
img {
  border: none;
}
li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}
alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15px;
  font-weight: bold;
  color: #FF0000;
}
em, i {
  font-style:italic;
}
div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}
div.spanner {
  clear: both;
}
div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}
div.paper div {
  padding-left: 230px;
}
img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}
span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}
pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}
div.paper pre {
  font-size: 0.9em;
}
</style>

<link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" /><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
</head>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-45959174-3', 'zzs1994.github.io');
  ga('send', 'pageview');
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');
</script>
<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
<div style="margin: 0px auto; width: 100%;">
<img title="Zhisheng" style="float: left; padding-left: .5em; height: 140px;" src="zhisheng.JPG" />
<div style="padding-left: 12em; vertical-align: top; height: 120px;"><span style="line-height: 150%; font-size: 20pt;">Zhisheng Zhong, 钟之声</span><br />
<!--<span><strong>Ph.D. Candidate</strong></span><br />-->
<!--<span><a href='http://cvrs.whu.edu.cn/'>Computer Vision & Remote Sensing (CVRS) Lab </a> <br /> </q>-->
<!--<span>Graduate School of Information Science and Technology, the University of Tokyo (IST, UTokyo)</span><br />-->
<span><strong>Email  </strong>:zszhong [at] pku.edu.cn </span><br/>
<span><strong><a href='https://github.com/zzs1994'>Github</a></strong>  &nbsp &nbsp &nbsp &nbsp
<strong><a href='https://scholar.google.com/citations?user=u-2_7C8AAAAJ&hl=en'>Google Scholar</a></strong> &nbsp &nbsp &nbsp &nbsp
<strong><a href='./Resume_EN_ZhishengZhong.PDF'>Resume</a></strong></span><br/>
<!-- <span><strong> <a href='https://github.com/kailigo'>Github</a> </strong></span> <br /> -->
<!-- <span><strong> <a href='https://scholar.google.com/citations?hl=en&user=YsROc4UAAAAJ'>Google Scholar</a> </strong></span> <br /> -->
</div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<div style="clear: both;">
<div class="section">
<h2>Short Biography</h2>
<div class="paper">
<p style="text-align:justify; text-justify:inter-ideograph;">
I graduated from <a href="http://english.pku.edu.cn">Peking University (PKU)</a>and during this period of time, I was fortunately directed by Prof. <a href="https://zhouchenlin.github.io/">Zhouchen Lin</a> and Prof. <a href="http://www.cis.pku.edu.cn/faculty/vision/zhangchao/zhangchao.htm/">Chao Zhang</a> at <a href="https://zero-lab-pku.github.io/">ZERO Lab</a>.
</p>

</div>
</div>
</div>
<!--
<div style="clear: both;">
<div class="section">
  <h2>News</h2>
  <div class="paper">
    <ul>
  <li> 2018.07: One paper is accepted by <strong> ECCV 2018 </strong>.</li> 
  <li> 2018.07: One paper is accepted by <strong> ACM MM 2018 </strong> .</li>  
  <li> 2019.07: Two papers are accepted by <strong> ICCV 2019 </strong>, one as <strong> Oral </strong> and one as Poster.</li>
  <li> 2019.06: One paper is accepted by <strong> TPAMI </strong>.</li> 
  <li> 2019.05: Start my internship at <strong> Bytedance AI Lab </strong> in Palo Alto.</li>
  <li> 2018.05: Start my internship at <strong> Adobe Research </strong> in San Jose.</li>      
  <li> 2018.03: One paper is accepted by <strong> CVPR 2018 </strong> as <strong> spotlight </strong>.</li>
  <li> 2017.05: Start my internship at <strong> Siemens Research </strong> in Princeton.</li> 
  <li> 2017.04: One paper is accepted by <strong> IJCAI 2017 </strong> .</li>   
  <li> 2016.09: Begin my new journey in <strong> Northeastern University </strong> at Boston.</li>   
    </ul>
  </div>
</div>
</div> -->




<!-- <div style="clear: both;">
<div class="section">
<h2 id="confpapers">Intern Experience</h2>


 -->


<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Publications</h2>


<div class="paper" id="DJSRH"><img class="paper" src="./pic/DJSRH.PNG" title="Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval">
<div> <strong>Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval</strong><br>
Shupeng Su*, <strong><u>Zhisheng Zhong*</u></strong>, Chao Zhang (* equal contributions)<br>
International Conference on Computer Vision (<strong>ICCV</strong>), 2019 <strong>(Oral, Top-4.3%)</strong>
<a href='http://openaccess.thecvf.com/content_ICCV_2019/papers/Su_Deep_Joint-Semantics_Reconstructing_Hashing_for_Large-Scale_Unsupervised_Cross-Modal_Retrieval_ICCV_2019_paper.pdf'>[PDF]</a>,
<a href='https://github.com/zzs1994/DJSRH'>[Code]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="EMANet"><img class="paper" src="./pic/EMANet.PNG" title="Expectation-Maximization Attention Networks for Semantic Segmentation">
<div> <strong>Expectation-Maximization Attention Networks for Semantic Segmentation</strong><br>
Xia Li, <strong><u>Zhisheng Zhong</u></strong>, Jianlong Wu, Yibo Yang, Zhouchen Lin, Hong Liu<br>
International Conference on Computer Vision (<strong>ICCV</strong>), 2019 <strong>(Oral, Top-4.3%)</strong>
<a href='https://arxiv.org/pdf/1907.13426.pdf'>[PDF]</a>, 
<a href='https://github.com/XiaLiPKU/EMANet'>[Code]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="DLADMM"><img class="paper" src="./pic/DLADMM.PNG" title="Differentiable Linearized ADMM">
<div> <strong>Differentiable Linearized ADMM</strong><br>
Xingyu Xie, Jianlong Wu, <strong><u>Zhisheng Zhong</u></strong>, Guangcan Liu, Zhouchen Lin<br>
International Conference on Machine Learning (<strong>ICML</strong>), 2019
<a href='https://arxiv.org/pdf/1905.06179.pdf'>[PDF]</a>,
<a href='https://github.com/zzs1994/D-LADMM'>[Code]</a>
</div>
<div class="spanner"></div>
</div>



<div class="paper" id="ADATucker"><img class="paper" src="./pic/ADATucker.PNG" title="ADA-Tucker: Compressing Deep Neural Networks via Adaptive Dimension Adjustment Tucker Decomposition">
<div> <strong>ADA-Tucker: Compressing Deep Neural Networks via Adaptive Dimension Adjustment Tucker Decomposition</strong><br>
<strong><u>Zhisheng Zhong</u></strong>, Fangyin Wei, Zhouchen Lin, Chao Zhang <br>
Neural Networks (<strong>NN</strong>), 2019
<a href='https://arxiv.org/pdf/1906.07671.pdf'>[PDF]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="SRCliqueNet"><img class="paper" src="./pic/SRCliqueNet.PNG" title="Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution">
<div> <strong>Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution</strong><br>
<strong><u>Zhisheng Zhong</u></strong>, Tiancheng Shen, Yibo Yang, Chao Zhang, Zhouchen Lin <br>
Neural Information Processing Systems (<strong>NIPS</strong>), 2018
<a href='https://arxiv.org/pdf/1809.04508.pdf'>[PDF]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="CliqueNet"><img class="paper" src="./pic/CliqueNet.PNG" title="Convolutional Neural Networks with Alternately Updated Clique">
<div> <strong>Convolutional Neural Networks with Alternately Updated Clique</strong><br>
Yibo Yang, <strong><u>Zhisheng Zhong</u></strong>, Tiancheng Shen, Zhouchen Lin <br>
Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2018 <strong>(Oral, Top-2.3%)</strong>
<a href='https://arxiv.org/pdf/1802.10419.pdf'>[PDF]</a>,
<a href='https://github.com/iboing/CliqueNet'>[Code]</a>
</div>
<div class="spanner"></div>
</div>



<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Selected Awards</h2>
<div class="paper">
    <ul>
      <!--<li> 2019 &nbsp &nbsp Monbukagakusho (MEXT) Scholarship, University of Tokyo (Top-1%)</li>-->
      <li> 2019 &nbsp &nbsp Qualcomm Scholarship, Peking University (Top-2%) </li>
      <li> 2019 &nbsp &nbsp Excellent Graduate, Peking University (Top-5%) </li>
      <li> 2018 &nbsp &nbsp Bao Steel Education Scholarship, Peking University (Top-5%)</li>
      <li> 2018 &nbsp &nbsp Merit Student, Peking University (Top-5%)</li>
      <li> 2016 &nbsp &nbsp Excellent Graduate, Beijing (Top-2%)</li>
      <li> 2015 &nbsp &nbsp National Encouragement Scholarship, Beijing (Top-5%)</li>
      <li> 2014 &nbsp &nbsp National Encouragement Scholarship, Beijing (Top-5%)</li>
      <li> 2013 &nbsp &nbsp First Prize, undergraduate physics competition, Beijing (Top-5%)</li>
      <li> 2013 &nbsp &nbsp First Prize, undergraduate mathematics competition, Beijing (Top-5%)</li>
</ul>
</div>
</div>
</div>

<!--<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Professonal Activities</h2>
<div class="paper">
<ul>
<p><font size="5">
  <li> Reviewer for CVPR 2019, 2020, ICCV 2019, AAAI 2019, 2020, TIP, TNNLS, TMI, TMM </li>        
</font></p>
</ul>
</div>
</div>
</div>-->



<!-- <div style="clear:both;">
<p align="right"><font size="5">Last Updated on 11th Dec, 2017</a></font></p>
<p align="right"><font size="5">Published with <a href='https://pages.github.com/'>GitHub Pages</a></font></p>
</div> -->

<!-- <hr> -->
<!-- <div id="clustrmaps-widget"></div><script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=IF-jAGUNTygi5pa59hxIgtJU2XqT-rGoO58Z3E1vHZk&cl=ffffff&w=a"></script> -->
<!--<div id="clustrmaps-widget"></div><script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=m&d=IF-jAGUNTygi5pa59hxIgtJU2XqT-rGoO58Z3E1vHZk'></script>-->
<!-- -->
</body>
</html>
>>>>>>> parent of 95560c5 (update)
